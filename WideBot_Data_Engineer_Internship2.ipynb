{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WideBot Data Engineer Internship2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BoWkrmoOGoq",
        "colab_type": "text"
      },
      "source": [
        "# Task 2 - Binary Classification Problem\n",
        "**Given the training and validation datasets, http://bit.ly/widebot-new-binclf-data , Create\n",
        "and train a machine learning model using the training set that performs well on the\n",
        "validation set. You should decide on the metrics of \"performance\" yourself, We will assess\n",
        "your decision.\n",
        "It is up to you to use any of the following languages: [Python, Scala, Java, R]. We\n",
        "appreciate a small write up of the observations and your thoughts to follow your thought\n",
        "process.**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XldIXzFJQOn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "fa90c85d-d4d7-44c2-9ebd-081cfbd07eca"
      },
      "source": [
        "# Import the dependencies\n",
        "import tensorflow as tf\n",
        " \n",
        "import numpy as np\n",
        "import pandas as pandas\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import random\n",
        "import csv as csv\n",
        "import gc\n",
        "gc.enable()\n",
        " \n",
        "print(tf.__version__)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkJ5Up2TQa0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e4abefb3-950b-47b0-9123-a2945b62e3c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_akuaaFQdW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To download the dataset.\n",
        "#!wget https://drive.google.com/u/0/uc?id=1JBnuP1GTXvhiTb80OEzN13uV7wMLkktg&export=download\n",
        "# # unzip the dataset to google drive.\n",
        "#!unzip uc?id=1JBnuP1GTXvhiTb80OEzN13uV7wMLkktg -d /content/drive/My\\ Drive/wideBot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZRR-j2owhJY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Firt we load and generate it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8C6a2MESFva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# class to load the dataset\n",
        "# and create data generator to get the result\n",
        "class DataLoader():\n",
        "  def __init__(self):  \n",
        "    \n",
        "    self.train_x, self.train_y = DataLoader.gen_data('/content/drive/My Drive/wideBot/training.csv', 'train')\n",
        "    self.valid_x, self.valid_y = DataLoader.gen_data('/content/drive/My Drive/wideBot/validation.csv', 'valid')\n",
        "    \n",
        "  def gen_data(url, distrib):\n",
        "    names = [\"variable1\", \"variable2\", \"variable3\", \"variable4\", \"variable5\", \"variable6\", \"variable7\", \"variable8\",\n",
        "             \"variable9\", \"variable10\", \"variable11\", \"variable12\", \"variable13\", \"variable14\", \"variable15\",\n",
        "             \"variable17\", \"variable18\", \"variable19\", \"classLabel\"]\n",
        "\n",
        "    train_data = pandas.read_csv(url, names=names , sep=\";\")\n",
        "    dataset = DataLoader.remove_NAN(train_data)\n",
        "    dataset = DataLoader.normalize_dataframe(dataset)\n",
        "    train_data = DataLoader.map_yes_no(dataset)\n",
        "\n",
        "    train_data = train_data.sample(frac=1).reset_index(drop=True)\n",
        "    train_x = train_data.drop(['classLabel'], axis=1)\n",
        "    train_x = DataLoader.fix_error(train_x, distrib)\n",
        "    train_y = train_data['classLabel']\n",
        "    return train_x, train_y\n",
        "\n",
        "  def fix_error(df, distrib):\n",
        "    if distrib == 'valid':\n",
        "        df['variable4_l'] = 0\n",
        "        df['variable5_gg'] = 0\n",
        "        df['variable6_r'] = 0\n",
        "        df['variable7_o'] = 0\n",
        "        df['variable13_p'] = 0\n",
        "    elif distrib == 'train':\n",
        "        df['variable4_l'] = df.pop('variable4_l')\n",
        "        df['variable5_gg'] = df.pop('variable5_gg')\n",
        "        df['variable6_r'] = df.pop('variable6_r')\n",
        "        df['variable7_o'] = df.pop('variable7_o')\n",
        "        df['variable13_p'] = df.pop('variable13_p')\n",
        "\n",
        "    return df\n",
        "\n",
        "  def remove_NAN(df):\n",
        "    # Drop NAs from variables of binary values\n",
        "    df = df.dropna(subset=['variable1', 'variable4', 'variable5', 'variable6', 'variable7'])\n",
        "\n",
        "    # Drop NAs from variables with low number of NAs\n",
        "    df = df.dropna(subset=['variable2', 'variable14', 'variable17'])\n",
        "\n",
        "    # Split Columns with comma (,) in its data\n",
        "    df['variable2_x'], df['variable2_y'] = df['variable2'].str.split(',', 1).str\n",
        "    df['variable3_x'], df['variable3_y'] = df['variable3'].str.split(',', 1).str\n",
        "    df['variable8_x'], df['variable8_y'] = df['variable8'].str.split(',', 1).str\n",
        "\n",
        "    # Removed Column: Variable18 which had a lot of NANs\n",
        "    # Rearrange columns after modifications\n",
        "    cols = ['variable1', 'variable2_x', 'variable2_y', 'variable3_x', 'variable3_y', 'variable4', 'variable5',\n",
        "            'variable6', 'variable7', 'variable8_x', 'variable8_y', 'variable9', 'variable10', 'variable11',\n",
        "            'variable12', 'variable13', 'variable14', 'variable15', 'variable17', 'variable19', 'classLabel']\n",
        "    df = df[cols]\n",
        "\n",
        "    num_col = ['variable2_x', 'variable2_y', 'variable3_x', 'variable3_y', 'variable8_x', 'variable8_y', 'variable11', 'variable14', 'variable15', 'variable17', 'variable19']\n",
        "\n",
        "    for i in num_col:\n",
        "        df[i] = df[i].astype(float)\n",
        "\n",
        "    # Remove NAs from splited columns\n",
        "    df['variable2_x'] = df['variable2_x'].fillna((df['variable2_x'].mean()))\n",
        "    df['variable3_x'] = df['variable3_x'].fillna((df['variable3_x'].mean()))\n",
        "    df['variable8_x'] = df['variable8_x'].fillna((df['variable8_x'].mean()))\n",
        "    df['variable2_y'] = df['variable2_y'].fillna((df['variable2_y'].mean()))\n",
        "    df['variable3_y'] = df['variable3_y'].fillna((df['variable3_y'].mean()))\n",
        "    df['variable8_y'] = df['variable8_y'].fillna((df['variable8_y'].mean()))\n",
        "\n",
        "    return df\n",
        "\n",
        "  def normalize_dataframe(df):\n",
        "    col_to_normalize = ['variable2_x', 'variable2_y', 'variable3_x', 'variable3_y', 'variable8_x', 'variable8_y',\n",
        "                     'variable11', 'variable14', 'variable15', 'variable17', 'variable19']\n",
        "    for i in col_to_normalize:\n",
        "        df[i] = (df[i] - df[i].mean()) / df[i].std()\n",
        "    return df\n",
        "\n",
        "  def map_yes_no(df):\n",
        "    cols_to_one_hot = ['variable1', 'variable4', 'variable5', 'variable6', 'variable7', 'variable9', 'variable10', 'variable12', 'variable13']\n",
        "    for i in cols_to_one_hot:\n",
        "        dummies = pandas.get_dummies(df[i], prefix=i, drop_first=False)\n",
        "        df = pandas.concat([df, dummies], axis=1)\n",
        "        df = df.drop([i], axis=1)\n",
        "    df['classLabel'] = df['classLabel'].map({'yes.': 1, 'no.': 0})\n",
        "    # Rearrange columns\n",
        "    df['classLabel'] = df.pop('classLabel')\n",
        "    return df\n",
        "\n",
        "  #return : data generator\n",
        "  def get_data_generator(self):\n",
        "    return self.train_x, self.train_y, self.valid_x, self.valid_y\n",
        " "
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IMVtsXCw8YD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Second create the model to train it**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtfjinWysEw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import random\n",
        "\n",
        "def print_model_specs(predictions, Y_test):\n",
        "    print(\"Accuracy is: \", accuracy_score(Y_test, predictions))\n",
        "    print(\"------------------------------------------------------------------\")\n",
        "    print(classification_report(Y_test, predictions))\n",
        "\n",
        "def choose_features(train_x, test_x, features):\n",
        "    \"\"\"\n",
        "    This function is used after testing with multiple set of features in the drop_features method,\n",
        "    and then choosing the set of features with the highest accuracy.\n",
        "    \"\"\"\n",
        "    ret_train_x = pandas.DataFrame()\n",
        "    ret_test_x = pandas.DataFrame()\n",
        "\n",
        "    for i in features:\n",
        "        ret_train_x[i] = train_x[i]\n",
        "        ret_test_x[i] = test_x[i]\n",
        "\n",
        "    return ret_train_x, ret_test_x\n",
        "\n",
        "def neural_model(X_train, X_test, Y_train):\n",
        "    classifier = MLPClassifier(solver='lbfgs', alpha=0.1, hidden_layer_sizes=(5, 5, 5, 2), random_state=1)\n",
        "    classifier.fit(X_train, Y_train)\n",
        "    predictions = classifier.predict(X_test)\n",
        "    return classifier, predictions\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hU39-yKkxHfM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**Finally, Train the model and test it with the validation test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t04Vn4JPKHOw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "03cdece9-cb8e-4dfd-da4b-460c1b3086b0"
      },
      "source": [
        "import random\n",
        "\n",
        "train_x, train_y, test_x, test_y = DataLoader().get_data_generator()\n",
        "all_columns = ['variable2_x', 'variable2_y', 'variable3_x', 'variable3_y',\n",
        "       'variable8_x', 'variable8_y', 'variable11', 'variable14', 'variable15',\n",
        "       'variable17', 'variable19', 'variable1_a', 'variable1_b', 'variable4_u',\n",
        "       'variable4_y', 'variable5_g', 'variable5_p', 'variable6_W',\n",
        "       'variable6_aa', 'variable6_c', 'variable6_cc', 'variable6_d',\n",
        "       'variable6_e', 'variable6_ff', 'variable6_i', 'variable6_j',\n",
        "       'variable6_k', 'variable6_m', 'variable6_q', 'variable6_x',\n",
        "       'variable7_bb', 'variable7_dd', 'variable7_ff', 'variable7_h',\n",
        "       'variable7_j', 'variable7_n', 'variable7_v', 'variable7_z',\n",
        "       'variable9_f', 'variable9_t', 'variable10_f', 'variable10_t',\n",
        "       'variable12_f', 'variable12_t', 'variable13_g', 'variable13_s',\n",
        "       'variable4_l', 'variable5_gg', 'variable6_r', 'variable7_o',\n",
        "       'variable13_p']\n",
        "chosen = random.choices(all_columns, k=40)\n",
        "\n",
        "train_x, test_x = choose_features(train_x, test_x, chosen)\n",
        "classifier, predictions = neural_model(train_x, test_x, train_y)\n",
        "print_model_specs(predictions, test_y)\n",
        "pandas.set_option('display.expand_frame_repr', False)\n",
        "print(chosen)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy is:  0.8848167539267016\n",
            "------------------------------------------------------------------\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.85      0.88        99\n",
            "           1       0.85      0.92      0.89        92\n",
            "\n",
            "    accuracy                           0.88       191\n",
            "   macro avg       0.89      0.89      0.88       191\n",
            "weighted avg       0.89      0.88      0.88       191\n",
            "\n",
            "['variable7_o', 'variable9_t', 'variable13_s', 'variable3_x', 'variable6_q', 'variable9_f', 'variable7_v', 'variable5_g', 'variable6_ff', 'variable6_aa', 'variable7_h', 'variable6_m', 'variable6_i', 'variable15', 'variable4_l', 'variable8_x', 'variable7_z', 'variable9_t', 'variable6_i', 'variable17', 'variable13_s', 'variable3_x', 'variable6_i', 'variable3_y', 'variable5_p', 'variable7_j', 'variable6_m', 'variable9_f', 'variable7_z', 'variable6_W', 'variable5_p', 'variable4_l', 'variable11', 'variable7_v', 'variable6_aa', 'variable6_W', 'variable6_aa', 'variable4_y', 'variable5_p', 'variable12_f']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwZFk8J0RpG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**The Results :**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpRBJieFxaz4",
        "colab_type": "text"
      },
      "source": [
        "**With num of K = 30**\n",
        "Accuracy is:  0.8219895287958116\n",
        "------------------------------------------------------------------\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.92      0.72      0.81        99\n",
        "           1       0.75      0.93      0.83        92\n",
        "\n",
        "    accuracy                           0.82       191\n",
        "    macro avg       0.84      0.83      0.82       191\n",
        "    weighted avg       0.84      0.82      0.82       191\n",
        "\n",
        "With Column :\n",
        "\n",
        "['variable7_bb', 'variable1_b', 'variable6_d', 'variable4_y', 'variable6_d', 'variable7_n',\n",
        "\n",
        " 'variable6_i', 'variable6_cc', 'variable8_x', 'variable13_s', 'variable14', 'variable4_u',\n",
        "\n",
        "  'variable10_t', 'variable6_e', 'variable8_x', 'variable6_q', 'variable5_p', 'variable9_t',\n",
        "\n",
        "   'variable6_i', 'variable7_bb', 'variable6_c', 'variable6_W', 'variable5_p', 'variable17',\n",
        "\n",
        "   'variable2_y', 'variable1_b', 'variable7_n', 'variable13_s', 'variable4_u', 'variable7_o']\n",
        "\n",
        "Accuracy is:  0.7853403141361257\n",
        "------------------------------------------------------------------\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.94      0.63      0.75        99\n",
        "           1       0.70      0.96      0.81        92\n",
        "\n",
        "    accuracy                           0.79       191\n",
        "    macro avg       0.82      0.79      0.78       191\n",
        "    weighted avg       0.83      0.79      0.78       191\n",
        "\n",
        "With Column :\n",
        "\n",
        "['variable4_y', 'variable17', 'variable6_x', 'variable1_a', 'variable5_p', 'variable5_g', 'variable8_x',\n",
        "\n",
        " 'variable6_cc', 'variable12_f', 'variable13_s', 'variable6_m', 'variable7_dd', 'variable7_n', 'variable9_f',\n",
        "\n",
        " 'variable1_a', 'variable7_h', 'variable6_c', 'variable3_x', 'variable9_t', 'variable6_r', 'variable6_c',\n",
        "\n",
        "  'variable7_h', 'variable13_p', 'variable7_j', 'variable8_x', 'variable6_e', 'variable1_a', 'variable6_x',\n",
        "  \n",
        "   'variable11', 'variable10_f']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-FaZ781XziXD",
        "colab_type": "text"
      },
      "source": [
        "**With num of K = 40**\n",
        "\n",
        "Accuracy is:  0.8848167539267016\n",
        "------------------------------------------------------------------\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.92      0.85      0.88        99\n",
        "           1       0.85      0.92      0.89        92\n",
        "\n",
        "    accuracy                           0.88       191\n",
        "    macro avg       0.89      0.89      0.88       191\n",
        "    weighted avg       0.89      0.88      0.88       191\n",
        "\n",
        "With Column :\n",
        "\n",
        "['variable7_o', 'variable9_t', 'variable13_s', 'variable3_x', 'variable6_q', 'variable9_f', 'variable7_v', 'variable5_g', 'variable6_ff', 'variable6_aa',\n",
        "\n",
        " 'variable7_h', 'variable6_m', 'variable6_i', 'variable15', 'variable4_l', 'variable8_x', 'variable7_z', 'variable9_t', 'variable6_i', 'variable17',\n",
        "\n",
        "  'variable13_s', 'variable3_x', 'variable6_i', 'variable3_y', 'variable5_p', 'variable7_j', 'variable6_m', 'variable9_f', 'variable7_z', 'variable6_W',\n",
        "  \n",
        "   'variable5_p', 'variable4_l', 'variable11', 'variable7_v', 'variable6_aa', 'variable6_W', 'variable6_aa', 'variable4_y', 'variable5_p', 'variable12_f']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpCW4FZDz4xx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}