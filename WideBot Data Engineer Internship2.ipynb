{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WideBot Data Engineer Internship2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOunoAwRgVVy/8rd9U4uISg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"-BoWkrmoOGoq","colab_type":"text"},"source":["# Task 2 - Binary Classification Problem\n","**Given the training and validation datasets, http://bit.ly/widebot-new-binclf-data , Create\n","and train a machine learning model using the training set that performs well on the\n","validation set. You should decide on the metrics of \"performance\" yourself, We will assess\n","your decision.\n","It is up to you to use any of the following languages: [Python, Scala, Java, R]. We\n","appreciate a small write up of the observations and your thoughts to follow your thought\n","process.**\n"]},{"cell_type":"code","metadata":{"id":"XldIXzFJQOn6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1596825135495,"user_tz":-120,"elapsed":1527,"user":{"displayName":"Nada Salama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgM0li2jooVo_xTUDCbOmtdgW0OLQIzoLTaJtpS=s64","userId":"12431211946354955440"}},"outputId":"5ef33cb8-0612-4268-9660-a52eea3d85f0"},"source":["# Import the dependencies\n","import tensorflow as tf\n"," \n","import numpy as np\n","import pandas as pandas\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","import random\n","from sklearn.impute import SimpleImputer\n","import csv as csv\n","import gc\n","gc.enable()\n"," \n","print(tf.__version__)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["2.3.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RkJ5Up2TQa0T","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":33},"executionInfo":{"status":"ok","timestamp":1596818986060,"user_tz":-120,"elapsed":3266,"user":{"displayName":"Nada Salama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgM0li2jooVo_xTUDCbOmtdgW0OLQIzoLTaJtpS=s64","userId":"12431211946354955440"}},"outputId":"dae6f8a3-e1fe-4e24-a855-13f7c9ade6cd"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u_akuaaFQdW8","colab_type":"code","colab":{}},"source":["# # download the dataset.\n","#!wget https://drive.google.com/u/0/uc?id=1JBnuP1GTXvhiTb80OEzN13uV7wMLkktg&export=download\n","# # unzip the dataset to google drive.\n","#!unzip uc?id=1JBnuP1GTXvhiTb80OEzN13uV7wMLkktg -d /content/drive/My\\ Drive/wideBot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8C6a2MESFva","colab_type":"code","colab":{}},"source":["# class to load the dataset\n","# and create 2 generators\n","# 1) train generator : it will generate the train dataset samples to train the model.el during the training.\n","class DataLoader():\n","  def __init__(self, oversampling= False, shuffle = True):  \n","    names = [\"variable1\", \"variable2\", \"variable3\", \"variable4\", \"variable5\", \"variable6\", \"variable7\", \"variable8\",\n","             \"variable9\", \"variable10\", \"variable11\", \"variable12\", \"variable13\", \"variable14\", \"variable15\",\n","             \"variable17\", \"variable18\", \"variable19\", \"classLabel\"]\n","    \n","    self.train_x, self.train_y = DataLoader.gen_data('/content/drive/My Drive/wideBot/training.csv')\n","\n","    valid_data = pandas.read_csv('/content/drive/My Drive/wideBot/validation.csv', names=names , sep=\";\")\n","    dataset = DataLoader.remove_NAN(valid_data)\n","    dataset = DataLoader.normalize_dataframe(dataset)\n","    valid_data = DataLoader.map_yes_no(dataset)\n","\n","    valid_data = valid_data.sample(frac=1).reset_index(drop=True)\n","    valid_x = valid_data.drop(['classLabel'], axis=1)\n","    self.valid_x = DataLoader.fix_encode_test(valid_x, 'valid')\n","    self.valid_y = valid_data['classLabel']\n","    \n","  def gen_data(url):\n","    names = [\"variable1\", \"variable2\", \"variable3\", \"variable4\", \"variable5\", \"variable6\", \"variable7\", \"variable8\",\n","             \"variable9\", \"variable10\", \"variable11\", \"variable12\", \"variable13\", \"variable14\", \"variable15\",\n","             \"variable17\", \"variable18\", \"variable19\", \"classLabel\"]\n","\n","    train_data = pandas.read_csv(url, names=names , sep=\";\")\n","    dataset = DataLoader.remove_NAN(train_data)\n","    dataset = DataLoader.normalize_dataframe(dataset)\n","    train_data = DataLoader.map_yes_no(dataset)\n","\n","    train_data = train_data.sample(frac=1).reset_index(drop=True)\n","    train_x = train_data.drop(['classLabel'], axis=1)\n","    train_x = DataLoader.fix_encode_test(train_x, 'train')\n","    train_y = train_data['classLabel']\n","    return train_x, train_y\n","\n","  def fix_encode_test(df, distrib):\n","    if distrib == 'valid':\n","        df['variable4_l'] = 0\n","        df['variable5_gg'] = 0\n","        df['variable6_r'] = 0\n","        df['variable7_o'] = 0\n","        df['variable13_p'] = 0\n","    elif distrib == 'train':\n","        df['variable4_l'] = df.pop('variable4_l')\n","        df['variable5_gg'] = df.pop('variable5_gg')\n","        df['variable6_r'] = df.pop('variable6_r')\n","        df['variable7_o'] = df.pop('variable7_o')\n","        df['variable13_p'] = df.pop('variable13_p')\n","\n","    return df\n","\n","  def remove_NAN(df):\n","    # Drop NAs from variables of binary values\n","    df = df.dropna(subset=['variable1', 'variable4', 'variable5', 'variable6', 'variable7'])\n","\n","    # Drop NAs from variables with low number of NAs\n","    df = df.dropna(subset=['variable2', 'variable14', 'variable17'])\n","\n","    # Split Columns with comma (,) in its data\n","    df['variable2_x'], df['variable2_y'] = df['variable2'].str.split(',', 1).str\n","    df['variable3_x'], df['variable3_y'] = df['variable3'].str.split(',', 1).str\n","    df['variable8_x'], df['variable8_y'] = df['variable8'].str.split(',', 1).str\n","\n","    # Removed Column: Variable18 which had a lot of NANs (2000+)\n","    # Rearrange columns after modifications\n","    cols = ['variable1', 'variable2_x', 'variable2_y', 'variable3_x', 'variable3_y', 'variable4', 'variable5',\n","            'variable6', 'variable7', 'variable8_x', 'variable8_y', 'variable9', 'variable10', 'variable11',\n","            'variable12', 'variable13', 'variable14', 'variable15', 'variable17', 'variable19', 'classLabel']\n","    df = df[cols]\n","\n","    num_col = ['variable2_x', 'variable2_y', 'variable3_x', 'variable3_y', 'variable8_x', 'variable8_y', 'variable11', 'variable14', 'variable15', 'variable17', 'variable19']\n","\n","    for i in num_col:\n","        df[i] = df[i].astype(float)\n","\n","    # Remove NAs from columns with # of NAs of 100+\n","    df['variable2_x'] = df['variable2_x'].fillna((df['variable2_x'].mean()))\n","    df['variable3_x'] = df['variable3_x'].fillna((df['variable3_x'].mean()))\n","    df['variable8_x'] = df['variable8_x'].fillna((df['variable8_x'].mean()))\n","    df['variable2_y'] = df['variable2_y'].fillna((df['variable2_y'].mean()))\n","    df['variable3_y'] = df['variable3_y'].fillna((df['variable3_y'].mean()))\n","    df['variable8_y'] = df['variable8_y'].fillna((df['variable8_y'].mean()))\n","\n","    return df\n","\n","  def normalize_dataframe(df):\n","    col_to_normalize = ['variable2_x', 'variable2_y', 'variable3_x', 'variable3_y', 'variable8_x', 'variable8_y',\n","                     'variable11', 'variable14', 'variable15', 'variable17', 'variable19']\n","    for i in col_to_normalize:\n","        df[i] = (df[i] - df[i].mean()) / df[i].std()\n","    return df\n","\n","  def map_yes_no(df):\n","    cols_to_one_hot = ['variable1', 'variable4', 'variable5', 'variable6', 'variable7', 'variable9', 'variable10', 'variable12', 'variable13']\n","    for i in cols_to_one_hot:\n","        dummies = pandas.get_dummies(df[i], prefix=i, drop_first=False)\n","        df = pandas.concat([df, dummies], axis=1)\n","        df = df.drop([i], axis=1)\n","    df['classLabel'] = df['classLabel'].map({'yes.': 1, 'no.': 0})\n","    # Rearrange columns\n","    df['classLabel'] = df.pop('classLabel')\n","    return df\n","\n","  #return : train generator\n","  def get_train_generator(self):\n","    return self.train_x, self.train_y, self.valid_x, self.valid_y\n"," \n","  #return : validation generator\n","  def get_valid_generator(self):\n","    return self.valid_generator\n"," \n","  #return : test generator\n","  def get_test_generator(self):\n","    return self.test_generator\n"," \n","  def get_class_weight(self):\n","    return self.class_weight\n"," \n","  def __del__(self):\n","    del self.csv_train\n","    del self.csv_test\n","    del self.train_generator\n","    del self.valid_generator\n","    del self.test_generator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wYboq9d5ZbR5","colab_type":"code","colab":{}},"source":["dataLoader = DataLoader()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RtfjinWysEw2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596847226976,"user_tz":-120,"elapsed":5032,"user":{"displayName":"Nada Salama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgM0li2jooVo_xTUDCbOmtdgW0OLQIzoLTaJtpS=s64","userId":"12431211946354955440"}}},"source":["from sklearn.metrics import classification_report\n","from sklearn.metrics import accuracy_score\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","import random\n","\n","def print_model_specs(predictions, Y_test):\n","    print(\"Accuracy is: \", accuracy_score(Y_test, predictions))\n","    print(\"------------------------------------------------------------------\")\n","    print(classification_report(Y_test, predictions))\n","\n","def choose_features(train_x, test_x, features):\n","    \"\"\"\n","    This function is used after testing with multiple set of features in the drop_features method,\n","    and then choosing the set of features with the highest accuracy.\n","    \"\"\"\n","    ret_train_x = pandas.DataFrame()\n","    ret_test_x = pandas.DataFrame()\n","\n","    for i in features:\n","        ret_train_x[i] = train_x[i]\n","        ret_test_x[i] = test_x[i]\n","\n","    return ret_train_x, ret_test_x\n","\n","def neural_model(X_train, X_test, Y_train):\n","    classifier = MLPClassifier(solver='lbfgs', alpha=0.1, hidden_layer_sizes=(5, 5, 5, 2), random_state=1)\n","    classifier.fit(X_train, Y_train)\n","    predictions = classifier.predict(X_test)\n","    return classifier, predictions\n"],"execution_count":92,"outputs":[]},{"cell_type":"code","metadata":{"id":"t04Vn4JPKHOw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"status":"ok","timestamp":1596847698224,"user_tz":-120,"elapsed":3177,"user":{"displayName":"Nada Salama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgM0li2jooVo_xTUDCbOmtdgW0OLQIzoLTaJtpS=s64","userId":"12431211946354955440"}},"outputId":"738f7e27-6e11-4077-881e-cd7ba412da82"},"source":["import random\n","\n","train_x, train_y, test_x, test_y = DataLoader().get_train_generator()\n","all_columns = ['variable2_x', 'variable2_y', 'variable3_x', 'variable3_y',\n","       'variable8_x', 'variable8_y', 'variable11', 'variable14', 'variable15',\n","       'variable17', 'variable19', 'variable1_a', 'variable1_b', 'variable4_u',\n","       'variable4_y', 'variable5_g', 'variable5_p', 'variable6_W',\n","       'variable6_aa', 'variable6_c', 'variable6_cc', 'variable6_d',\n","       'variable6_e', 'variable6_ff', 'variable6_i', 'variable6_j',\n","       'variable6_k', 'variable6_m', 'variable6_q', 'variable6_x',\n","       'variable7_bb', 'variable7_dd', 'variable7_ff', 'variable7_h',\n","       'variable7_j', 'variable7_n', 'variable7_v', 'variable7_z',\n","       'variable9_f', 'variable9_t', 'variable10_f', 'variable10_t',\n","       'variable12_f', 'variable12_t', 'variable13_g', 'variable13_s',\n","       'variable4_l', 'variable5_gg', 'variable6_r', 'variable7_o',\n","       'variable13_p']\n","chosen = random.choices(all_columns, k=30)\n","\n","train_x, test_x = choose_features(train_x, test_x, chosen)\n","classifier, predictions = neural_model(train_x, test_x, train_y)\n","print_model_specs(predictions, test_y)\n","pandas.set_option('display.expand_frame_repr', False)\n","print(chosen)"],"execution_count":112,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:56: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: FutureWarning: Columnar iteration over characters will be deprecated in future releases.\n","Exception ignored in: <bound method DataLoader.__del__ of <__main__.DataLoader object at 0x7fd5b9414470>>\n","Traceback (most recent call last):\n","  File \"<ipython-input-84-f5c1b2570ef1>\", line 115, in __del__\n","AttributeError: csv_train\n"],"name":"stderr"},{"output_type":"stream","text":["Accuracy is:  0.8219895287958116\n","------------------------------------------------------------------\n","              precision    recall  f1-score   support\n","\n","           0       0.92      0.72      0.81        99\n","           1       0.75      0.93      0.83        92\n","\n","    accuracy                           0.82       191\n","   macro avg       0.84      0.83      0.82       191\n","weighted avg       0.84      0.82      0.82       191\n","\n","['variable7_bb', 'variable1_b', 'variable6_d', 'variable4_y', 'variable6_d', 'variable7_n', 'variable6_i', 'variable6_cc', 'variable8_x', 'variable13_s', 'variable14', 'variable4_u', 'variable10_t', 'variable6_e', 'variable8_x', 'variable6_q', 'variable5_p', 'variable9_t', 'variable6_i', 'variable7_bb', 'variable6_c', 'variable6_W', 'variable5_p', 'variable17', 'variable2_y', 'variable1_b', 'variable7_n', 'variable13_s', 'variable4_u', 'variable7_o']\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mJvZOAmqKn_8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596847239859,"user_tz":-120,"elapsed":5053,"user":{"displayName":"Nada Salama","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgM0li2jooVo_xTUDCbOmtdgW0OLQIzoLTaJtpS=s64","userId":"12431211946354955440"}}},"source":["Accuracy is:  0.8010471204188482\n","['variable4_y', 'variable17', 'variable6_x', 'variable1_a', 'variable5_p', 'variable5_g', 'variable8_x', 'variable6_cc', 'variable12_f', 'variable13_s', 'variable6_m', \n"," 'variable7_dd', 'variable7_n', 'variable9_f', 'variable1_a', 'variable7_h', 'variable6_c', 'variable3_x', 'variable9_t', 'variable6_r', 'variable6_c', 'variable7_h',\n"," 'variable13_p', 'variable7_j', 'variable8_x', 'variable6_e', 'variable1_a', 'variable6_x', 'variable11', 'variable10_f']\n"],"execution_count":94,"outputs":[]}]}